
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>PCV_FoV_Prediction</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="PCV_FoV_Prediction" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="https://chenli1996.github.io/PCV_FoV_Prediction/" />
<meta property="og:url" content="https://chenli1996.github.io/PCV_FoV_Prediction/" />
<meta property="og:site_name" content="PCV_FoV_Prediction" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="PCV_FoV_Prediction" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","headline":"PCV_FoV_Prediction","name":"PCV_FoV_Prediction","url":"https://chenli1996.github.io/PCV_FoV_Prediction/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/PCV_FoV_Prediction/assets/css/style.css?v=d4c2e1349bec8f79d779f7a0975e1bb1de7a5bba">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/PCV_FoV_Prediction/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="https://chenli1996.github.io/PCV_FoV_Prediction/">PCV_FoV_Prediction</a></h1>
      

      <!-- MathJax Configuration -->
<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>

<!-- MathJax CDN -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async=""></script>

<p>Paper Link:</p>

<h1 id="abstract">Abstract</h1>

<p>Field-of-View (FoV) adaptive streaming significantly reduces bandwidth requirement of immersive point cloud   video (PCV) by only transmitting visible points in a viewer’s FoV. The traditional approaches often focus on trajectory-based 6 degree-of-freedom (6DoF) FoV predictions. The predicted FoV is then used to calculate point visibility. Such approaches do not explicitly consider video content’s impact on viewer attention, and the conversion from FoV to point visibility is often error-prone and time-consuming. We reformulate the PCV FoV prediction problem from the cell visibility perspective, allowing for precise decision-making regarding the transmission of 3D data at the cell level based on the predicted visibility distribution. We develop a novel spatial visibility and object-aware graph model that leverages the historical 3D visibility data and incorporates spatial perception, neighboring cell correlation, and occlusion information to predict the cell visibility in the future. 
Our model significantly improves the long-term cell  visibility prediction, reducing the prediction MSE loss by up to 50% compared to the state-of-the-art models while maintaining real-time performance (more than 30fps) for point cloud videos with over 1 million points.</p>

<h1 id="introduction">Introduction</h1>
<p>AR/VR applications are rapidly growing, with immersive video streaming—such as 360-degree and point cloud videos—being essential for widespread adoption. These videos require significantly higher bandwidth than traditional 2D videos; for example, a point cloud video with 300k to 1M points demands 1.08 Gbps to 3.6 Gbps. A solution is Field of View (FoV) adaptive streaming, which transmits only the video content within the viewer’s viewport, reducing bandwidth by as much as six times for 360-degree videos.</p>

<p>However, accurately predicting the viewer’s future FoV is challenging, as it requires a buffer of 2 to 5 seconds for smooth streaming. Current methods typically involve predicting the viewport based on past trajectories, which can lead to errors. We propose a direct approach to predict cell visibility using the viewer’s trajectory, historical visibility, and spatial features of the objects. This method can reduce error amplification and leverage continuity in visibility changes. Our framework improves long-term visibility prediction accuracy by up to 50% in real-time using actual point cloud video and viewport trajectory datasets.</p>



<h1 id="conclusion">Conclusion</h1>

<p>In this paper, we introduce a novel spatial-based FoV prediction approach designed to predict long-term cell visibility for PCV. Our method leverages both spatial and temporal dynamics of PCV objects and viewers, outperforming existing state-of-the-art methods in terms of prediction accuracy and robustness. By integrating Transformer-based GNNs and graph attention networks, our model efficiently captures complex relationships between neighboring cells with a single graph layer. This approach overcomes the limitations of trajectory-based FoV prediction by incorporating the full spatial context, resulting in more accurate and stable predictions. Our spatial-based FoV prediction model presents a promising solution for long-term 6-DoF FoV prediction, immersive video streaming, and 3D rendering. We will make the code available to support further research and development in this area.</p>


      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
  </body>
</html>
